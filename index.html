<!DOCTYPE HTML>
<html>
	<head>
		<title>Full-Stack, GPU-based Acceleration of Deep Learning</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />		
		<link rel="stylesheet" type="text/css" href="data/stylesheet.css">
		<link rel="stylesheet" href="data/academicons-1.9.1/css/academicons.css" />
		<link rel="stylesheet" href="data/fontawesome-free-6.0.0-web/css/all.css">
	</head>
	<body>
		
		<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>										
			<p style="text-align:center">
				<name>Full-Stack, GPU-based Acceleration of Deep Learning</name>			
			  </p>			  
			  <p style="text-align:center">
				<img src="data/nvidia.png" alt="Nvidia" style="width:100px;max-width:15%;min-width:75px">					  
				</p>				
			<tr style="padding:0px">
			<td style="padding:0px">				
			  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				<tr style="padding:0px">  
				  <td style="width:80%;vertical-align:top">
					<p style="text-align:center">
						<font size="+4">Room 205 A, Music Hall 
						<br>Thu Jun 12th 1 p.m. to 5 p.m. </br>
						<br>Nashville</br>
						</font>
				  </p>
														      					  
					  <p style="text-align:left">
	  					  <font size="+2">Summary</font>
					  </p>
					  This year, the tutorial focuses on describing techniques to allow deep learning practitioners to accelerate the training and inference of large deep transformer networks while also reducing memory requirements across a spectrum of off-the-shelf hardware for important applications such as autonomous driving and large language models. Topics include, but are not limited to:
                      <ul>
					<li>Deep learning specialized hardware overview. We will review the architecture of most commonly used deep
						learning acceleration hardware: GPU and TPU. We will cover main computational processors and memory
						modules.</li>
						<li>How deep learning is performed on this hardware. We will cover aspects of algorithmic intensity and
						provide overview of theoretical aspects of compute. Attendees will learn how to estimate processing time and
						latency by looking only at hardware specs and the network architecture.</li>
						<li>Best practices for acceleration. We will provide an overview of best practices to design efficient neural
						networks. Topics of interest will include guidance for channel number selection, compute heavy operations,
						reduction operations etc.</li>
						<li>Existing tools for model acceleration. In this part we will focus on existing tools to accelerate a trained
						neural network on GPU devices. Particularly, we will discuss operation folding, TensorRT, ONNX graph
						optimization, sparsity.</li>
						<li>Research overview of recent techniques. This part will cover most recent advanced techniques for post
						training model optimization with the focus on most recent works (past 4 years). Range of topics will include
						pruning, quantization, model distillation, NAS etc.</li>
					    <li>Foundation models. This part will cover most recent advanced techniques for training and deploying foun-
							dation models efficiently.</li>
							                    </ul>
					  <br>
				  </td>				  
				</tr>
			  </tbody>
			</table>
		  <hr>
		  <div>					
			<div></div>
				<h2><font size="+2">Schedule</font> </h2>								
				<table>
					<tr>
					  <td>13:00</td><td>13:05</td><td></td><td>Opening Remarks</td>
					  </tr><tr>
						<td>13:05</td><td>14:30</td> <td></td> <td>Jason Clemons</td> <td></td> <td>Understanding Hardware For Optimization.</td>
					  </tr>
					  <tr>
					  <td>14:40</td><td>15:15</td> <td></td> <td>Alex Sun<td>  <td>  </td>
					  </tr>
					   <tr>
					   <td>15:30</td><td>16:30</td><td> <td>Hongxu (Danny) Yin</td><td></td><td>Efficient Vision Language Models.</td>
					</tr>
					<tr>  
					   <td>16:30</td><td>17:00</td><td></td><td>Q&A and Closing Remarks</td>
					</tr>
				  </table>
								
			</div>		
			<hr>
			<div>
				<h2><font size="+2">Instructors</font> </h2>								
			<p align="center">
<!--			<img src="./data/maying.png" width="125" height="150" title="Maying Shen">
			<img src="./data/clemons.jpg" width="125"  height="150" title="Jason Clemons">
			<img src="./data/hongxu.png" width="125" height="150" title="Danny Yin">
			<img src="./data/Pavlo_Molchanov.png" width="125" height="150" title="Pavlo Molchanov">
			-->
			<table>
				<tr>
					<td><img src="./data/AlexSun.png" width="125" height="150" title="Maying Shen"></td><td>		
						Alex (Xinglong) Sun is an AI researcher at the Applied AV Research team at NVIDIA. Prior to joining NVIDIA, Alex pursued his graduate studies and research at Stanford and UIUC majoring in computer science. He is interested in efficient deep learning, visual perception, and end-to-end autonomous driving.</td>
<!--				  <td><img src="./data/maying.png" width="125" height="150" title="Maying Shen"></td><td>		
					Maying Shen is currently a senior autonomous driving research engineer at NVIDIA. Prior to joining NVIDIA,
	she graduated from CMU majoring in computer vision, where she developed her interest in seeing the world through
	the computer's eyes. Her interests include deep learning efficiency from both, training and inference side, working
	on aspects such as neural network pruning, distillation, or quantization among others.</td>
	</tr>
	-->
	<tr>			  <td>	<img src="./data/clemons.jpg" width="125"  height="150" title="Jason Clemons"></td><td>
		Jason Clemons received his Ph.D. in computer science and engineering from the University of Michigan, Ann
		Arbor, MI, USA where he researched computer architectures for mobile computer vision. In his senior research
		scientist role at NVIDIA his current research focuses on domain-specific computing, in particular the intersection
		of machine learning, computer vision, and computer architecture. He has worked on machine learning accelerators,
		computer vision accelerators, accelerating DNN training on GPUs, and accelerating RL using GPUs. He is an IEEE
		senior member and serves on IEEE International Symposium on Performance Analysis of Systems and Software
		steering committee.</td>
	  </tr>
				  <tr>			  <td>	<img src="./data/hongxu.png" width="125" height="150" title="Danny Yin"></td><td>
					Hongxu (Danny) Yin is a senior research scientist at Learning and Perception Research (LPR) at NVIDIA. He
					obtained his Ph.D. at Princeton University, New Jersey, USA, and B. Eng. from Nanyang Technological University, Singapore. He is a recipient of Princeton Yan Huo 94* Graduate Fellowship, Princeton Best Dissertation
					Finalist within Department, Princeton Natural Sciences and Engineering Fellowship, Defense Science & Technology Agency gold medal, and Thomson Asia Pacific Holdings gold medal. His research interests mainly include
					data-/execution-efficient and secure deep learning overseeing CNNs and transformers. He has been the organizer
					of several tutorial/workshop at CVPR and ICCV. He has been featured as Global Outstanding Chinese Power 100
					Award by 36Kr and Top 60 Elite Chinese in North America by Forbes.</td>
				  </tr>
				 
				</table>
									
			</div>		
	
	</p>
		</div>		
		<hr>
		<div>
			<h2><font size="+2">Organizers</font> </h2>								
			<ul> 
			<li>Maying Shen, Senior Research Engineer
			<li>Jason Clemons, Senior Research Scientist
			<li>Hongxu (Danny) Yin, Senior Research Scientist
			<li>Pavlo Molchanov, Director of research 
			<li>Jose M. Alvarez, Director of research 
			<li>Jan Kautz, VP of research
			</ul> 
		</div>		


		</td>
	</tr>
</table>      
    </section>
  </div>


</body>  			  		  
</html>