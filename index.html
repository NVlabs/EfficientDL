<!DOCTYPE HTML>
<html>
	<head>
		<title>Full-Stack, GPU-based Acceleration of Deep Learning</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />		
		<link rel="stylesheet" type="text/css" href="data/stylesheet.css">
		<link rel="stylesheet" href="data/academicons-1.9.1/css/academicons.css" />
		<link rel="stylesheet" href="data/fontawesome-free-6.0.0-web/css/all.css">
	</head>
	<body>
		
		<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>										
			<p style="text-align:center">
				<name>Full-Stack, GPU-based Acceleration of Deep Learning</name>			
			  </p>			  
			  <p style="text-align:center">
				<img src="data/nvidia.png" alt="Nvidia" style="width:100px;max-width:15%;min-width:75px">					  
				</p>			
		<!--	<p style="text-align:center">
				<img src="data/audience.png" alt="attendance" style="width:800px;max-width:100%;min-width:800px">
			</p>
		-->			
			<tr style="padding:0px">
			<td style="padding:0px">				
			  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				<tr style="padding:0px">  
				  <td style="width:80%;vertical-align:top">									      					  
					  <p style="text-align:left">
	  					  <font size="+2">Summary</font>
					  </p>
					  This tutorial focuses on describing techniques to allow deep learning practitioners to accelerate the training and inference of large deep networks while also reducing memory requirements across a spectrum of off-the-shelf hardware for important applications such as autonomous driving and large language models. Topics include, but are not limited to:
                      <ul>
					    <li>Deep learning specialized hardware overview. We review the architecture of the most used deep learning acceleration hardware, including the main computational processors and memory modules.</li>
                        <li>How deep learning is performed on this hardware. We cover aspects of algorithmic intensity and an overview of theoretical aspects of computing. Attendees will learn how to estimate processing time and latency by looking only at hardware specs and the network architecture.</li>
                        <li>Best practices for acceleration. We provide an overview of best practices for designing efficient neural networks including channel number selection, compute heavy operations, or reduction operations among others.</li>
                        <li>Existing tools for model acceleration. In this part we will focus on existing tools to accelerate a trained neural network on GPU devices. We will particularly discuss operation folding, TensorRT, ONNX graph optimization, sparsity.</li>
                        <li>Research overview of recent techniques. In the last part, we will focus on recent advanced techniques for post training model optimization including pruning, quantization, model distillation or NAS among others.</li>
                    </ul>
					  <br>
				  </td>				  
				</tr>
			  </tbody>
			</table>
		  <hr>
		  <div>					
			<div></div>
				<h2><font size="+2">Schedule</font> </h2>								
				<table>
					<tr>
					  <td>13:30</td><td>13:35</td><td></td><td>Opening Remarks</td>
					  </tr><tr>
						<td>13:35</td><td>14:30</td> <td></td> <td>Jason Clemons</td> <td></td> <td> Foundations of DL Hardware And How to Apply Them.</td>
					  </tr>
					  <tr>
					  <td>14:35</td><td>15:30</td> <td></td> <td>Maying Shen<td>  <td>Neural Network Acceleration.</td>
					  </tr>
					  <tr>
					  <td>15:00</td><td>15:30</td><td></td><td>Coffee Break</td><td></td>
					  </tr>
					   <tr>
					   <td>15:30</td><td>16:30</td><td> <td>Hongxu (Danny) Yin</td><td></td><td>Efficient Vision Language Models.</td>
					</tr>
					<tr>  
					   <td>16:30</td><td>16:35</td><td></td><td>Closing Remarks</td>
					</tr>
				  </table>
								
			</div>		
			<hr>
			<div>
				<h2><font size="+2">Instructors</font> </h2>								
			<p align="center">
<!--			<img src="./data/maying.png" width="125" height="150" title="Maying Shen">
			<img src="./data/clemons.jpg" width="125"  height="150" title="Jason Clemons">
			<img src="./data/hongxu.png" width="125" height="150" title="Danny Yin">
			<img src="./data/Pavlo_Molchanov.png" width="125" height="150" title="Pavlo Molchanov">
			-->
			<table>
				<tr>
				  <td><img src="./data/maying.png" width="125" height="150" title="Maying Shen"></td><td>		
					Maying Shen is currently a senior autonomous driving research engineer at NVIDIA. Prior to joining NVIDIA,
	she graduated from CMU majoring in computer vision, where she developed her interest in seeing the world through
	the computer's eyes. Her interests include deep learning efficiency from both, training and inference side, working
	on aspects such as neural network pruning, distillation, or quantization among others.</td>
	</tr>
	<tr>			  <td>	<img src="./data/clemons.jpg" width="125"  height="150" title="Jason Clemons"></td><td>
		Jason Clemons received his Ph.D. in computer science and engineering from the University of Michigan, Ann
		Arbor, MI, USA where he researched computer architectures for mobile computer vision. In his senior research
		scientist role at NVIDIA his current research focuses on domain-specific computing, in particular the intersection
		of machine learning, computer vision, and computer architecture. He has worked on machine learning accelerators,
		computer vision accelerators, accelerating DNN training on GPUs, and accelerating RL using GPUs. He is an IEEE
		senior member and serves on IEEE International Symposium on Performance Analysis of Systems and Software
		steering committee.</td>
	  </tr>
				  <tr>			  <td>	<img src="./data/hongxu.png" width="125" height="150" title="Danny Yin"></td><td>
					Hongxu (Danny) Yin is a senior research scientist at Learning and Perception Research (LPR) at NVIDIA. He
					obtained his Ph.D. at Princeton University, New Jersey, USA, and B. Eng. from Nanyang Technological University, Singapore. He is a recipient of Princeton Yan Huo 94* Graduate Fellowship, Princeton Best Dissertation
					Finalist within Department, Princeton Natural Sciences and Engineering Fellowship, Defense Science & Technology Agency gold medal, and Thomson Asia Pacific Holdings gold medal. His research interests mainly include
					data-/execution-efficient and secure deep learning overseeing CNNs and transformers. He has been the organizer
					of several tutorial/workshop at CVPR and ICCV. He has been featured as Global Outstanding Chinese Power 100
					Award by 36Kr and Top 60 Elite Chinese in North America by Forbes.</td>
				  </tr>
				 
				</table>
									
			</div>		
	
	</p>
		</div>		
		<hr>
		<div>
			<h2><font size="+2">Organizers</font> </h2>								
			<ul> 
			<li>Maying Shen, Senior Research Engineer
			<li>Jason Clemons, Senior Research Scientist
			<li>Hongxu (Danny) Yin, Senior Research Scientist
			<li>Pavlo Molchanov, Principal Research Scientist
			<li>Jose M. Alvarez, Director, Applied research 
			<li>Jan Kautz, VP of research
			</ul> 
		</div>		


		</td>
	</tr>
</table>      
    </section>
  </div>


</body>  			  		  
</html>